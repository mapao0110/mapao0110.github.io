<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小马&amp;博客</title>
  
  <subtitle>不爱码字的小懒马儿</subtitle>
  <link href="https://mapao0110.github.io/atom.xml" rel="self"/>
  
  <link href="https://mapao0110.github.io/"/>
  <updated>2023-11-14T08:43:57.145Z</updated>
  <id>https://mapao0110.github.io/</id>
  
  <author>
    <name>马跑</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ResNet</title>
    <link href="https://mapao0110.github.io/2023/11/14/ResNet/"/>
    <id>https://mapao0110.github.io/2023/11/14/ResNet/</id>
    <published>2023-11-14T05:06:02.000Z</published>
    <updated>2023-11-14T08:43:57.145Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：ResNet网络结构详解与迁移学习<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、ResNet 详解<br>（1）ResNet 网络是在 2015年 由微软实验室提出，斩获当年ImageNet竞赛中分类任务第一名，目标检测第一名。获得COCO数据集中目标检测第一名，图像分割第一名。<br>（2）ResNet网络的创新点：<br>&emsp; * 提出 Residual 结构（残差结构），并搭建超深的网络结构（可突破1000层）。<br>&emsp; * 使用 Batch Normalization 加速训练（丢弃dropout）。</p><p>2、Why residual?<br>（1）在ResNet网络提出之前，传统的卷积神经网络都是通过将一系列卷积层与池化层进行堆叠得到的。<br>（2）一般我们会觉得网络越深，特征信息越丰富，模型效果应该越好。但是实验证明，当网络堆叠到一定深度时，会出现两个问题：<br>&emsp; 梯度消失或梯度爆炸：<br>&emsp; * 若每一层的误差梯度小于1，反向传播时，网络越深，梯度越趋近于0<br>&emsp; * 反之，若每一层的误差梯度大于1，反向传播时，网路越深，梯度越来越大<br>&emsp; 退化问题(degradation problem)：<br>&emsp; * 在解决了梯度消失、爆炸问题后，仍然存在深层网络的效果可能比浅层网络差的现象<br>&emsp; 当网络堆叠到一定深度时，反而会出现深层网络比浅层网络效果差的情况。<br>&emsp; 如下图所示，20层网络 反而比 56层网络 的误差更小：<br><img src="/pic/ResNet/rs01.png"><br>&emsp; 对于梯度消失或梯度爆炸问题，ResNet论文提出通过数据的预处理以及在网络中使用 BN（Batch Normalization）层来解决。<br>&emsp; 对于退化问题，ResNet论文提出了 residual结构（残差结构）来减轻退化问题，下图是使用residual结构的卷积网络，可以看到随着网络的不断加深，效果并没有变差，而是变的更好了。（虚线是train error，实线是test error）<br><img src="/pic/ResNet/rs02.png"></p><p>3、What is residual？<br>（1）为了解决深层网络中的退化问题，可以人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为 残差网络 (ResNets)。<br>（2）残差网络由许多隔层相连的神经元子模块组成，我们称之为 残差块 Residual block。单个残差块的结构如下图所示：<br><img src="/pic/ResNet/rs03.png"><br><img src="/pic/ResNet/rs04.jpg"></p><p>4、ResNet中的残差结构<br>（1）实际应用中，残差结构的 short cut 不一定是隔一层连接，也可以中间隔多层，ResNet所提出的残差网络中就是隔多层。<br>（2）下图中左侧残差结构称为 BasicBlock，右侧残差结构称为 Bottleneck<br><img src="/pic/ResNet/rs05.png"><br>对于深层的 Bottleneck，1×1的卷积核起到降维和升维（特征矩阵深度）的作用，同时可以大大减少网络参数。<br><img src="/pic/ResNet/rs06.jpg"></p><p>5、降维时的 short cut<br>（1）观察下图的 ResNet18层网络，可以发现有些残差块的 short cut 是实线的，而有些则是虚线的。这些虚线的 short cut 上通过1×1的卷积核进行了维度处理（特征矩阵在长宽方向降采样，深度方向调整成下一层残差结构所需要的channel）。<br><img src="/pic/ResNet/rs07.png"></p><p>6、迁移学习简介<br>（1）迁移学习是一个比较大的领域，我们这里说的迁移学习是指神经网络训练中使用到的迁移学习。<br>（2）在迁移学习中，我们希望利用源任务（Source Task）学到的知识帮助学习目标任务 (Target Task)。例如，一个训练好的图像分类网络能够被用于另一个图像相关的任务。再比如，一个网络在仿真环境学习的知识可以被迁移到真实环境的网络。迁移学习一个典型的例子就是载入训练好VGG网络，这个大规模分类网络能将图像分到1000个类别，然后把这个网络用于另一个任务，如医学图像分类。<br>（3）为什么可以这么做呢？如下图所示，神经网络逐层提取图像的深层信息，这样，预训练网络就相当于一个特征提取器。<br><img src="/pic/ResNet/rs08.png"><br>（4）使用迁移学习的优势：<br>&emsp; * 能够快速的训练出一个理想的结果<br>&emsp; * 当数据集较小时也能训练出理想的效果<br>&emsp; （注意：使用别人预训练好的模型参数时，要注意别人的预处理方式。）<br>（5）常见的迁移学习方式：<br>&emsp; * 载入权重后训练所有参数<br>&emsp; * 载入权重后只训练最后几层参数<br>&emsp; * 载入权重后在原网络基础上再添加一层全连接层，仅训练最后一个全连接层<br><img src="/pic/ResNet/rs09.png"></p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：ResNet网络结构详解与迁移学习</summary>
    
    
    
    <category term="研究方向(学习路线_记忆宫殿)" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91-%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="阶段四：图像分类实战" scheme="https://mapao0110.github.io/tags/%E9%98%B6%E6%AE%B5%E5%9B%9B%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>GoogLeNet</title>
    <link href="https://mapao0110.github.io/2023/11/13/GoogLeNet/"/>
    <id>https://mapao0110.github.io/2023/11/13/GoogLeNet/</id>
    <published>2023-11-13T10:58:53.000Z</published>
    <updated>2023-11-13T11:26:35.483Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：GoogLeNet结构详解<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、关于GoogLeNet网络<br>（1）GoogLeNet在2014年由Google团队提出（与VGG网络同年，注意GoogLeNet中的L大写是为了致敬LeNet），斩获当年ImageNet竞赛中Classification Task (分类任务) 第一名。<br>（2）GoogLeNet 的创新点：<br>&emsp; * 引入了 Inception 结构（融合不同尺度的特征信息）<br>&emsp; * 使用1x1的卷积核进行降维以及映射处理 （虽然VGG网络中也有，但该论文介绍的更详细）<br>&emsp; * 添加两个辅助分类器帮助训练<br>&emsp; * 丢弃全连接层，使用平均池化层（大大减少模型参数，除去两个辅助分类器，网络大小只有vgg的1/20）</p><p>2、inception 结构<br>（1）传统的CNN结构如AlexNet、VggNet都是串联的结构，即将一系列的卷积层和池化层进行串联得到的结构。<br>（2）GoogLeNet 提出了一种并联结构，下图是论文中提出的inception原始结构，将特征矩阵同时输入到多个分支进行处理，并将输出的特征矩阵按深度进行拼接，得到最终输出。<br><img src="/pic/GoogLeNet/inception.png" alt="inception"><br>&emsp; * inception的作用：增加网络深度和宽度的同时减少参数。<br>&emsp; * 注意：每个分支所得特征矩阵的高和宽必须相同（通过调整stride和padding），以保证输出特征能在深度上进行拼接。</p><p>3、inception + 降维<br>（1）在 inception 的基础上，还可以加上降维功能的结构，如下图所示，在原始 inception 结构的基础上，在分支2，3，4上加入了卷积核大小为1x1的卷积层，目的是为了降维（减小深度），减少模型训练参数，减少计算量。<br><img src="/pic/GoogLeNet/inception02.png" alt="inception + 降维"><br>（2）1×1卷积核的降维功能<br>&emsp; 同样是对一个深度为512的特征矩阵使用64个大小为5x5的卷积核进行卷积，不使用1x1卷积核进行降维的 话一共需要819200个参数，如果使用1x1卷积核进行降维一共需要50688个参数，明显少了很多。<br><img src="/pic/GoogLeNet/jc.png" alt="降维功能"><br>&emsp; * 注：CNN参数个数 = 卷积核尺寸×卷积核深度 × 卷积核组数 = 卷积核尺寸 × 输入特征矩阵深度 × 输出特征矩阵深度</p><p>4、辅助分类器（Auxiliary Classifier）<br>（1）AlexNet 和 VGG 都只有1个输出层，GoogLeNet 有3个输出层，其中的两个是辅助分类层。<br>（2）如下图所示，网络主干右边的 两个分支 就是 辅助分类器，其结构一模一样。在训练模型时，将两个辅助分类器的损失乘以权重（论文中是0.3）加到网络的整体损失上，再进行反向传播。<br><img src="/pic/GoogLeNet/GoogLeNet.png" alt="GoogLeNet"></p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：GoogLeNet结构详解</summary>
    
    
    
    <category term="研究方向(学习路线_记忆宫殿)" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91-%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="阶段四：图像分类实战" scheme="https://mapao0110.github.io/tags/%E9%98%B6%E6%AE%B5%E5%9B%9B%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>VGG网络</title>
    <link href="https://mapao0110.github.io/2023/11/13/VGG%E7%BD%91%E7%BB%9C/"/>
    <id>https://mapao0110.github.io/2023/11/13/VGG%E7%BD%91%E7%BB%9C/</id>
    <published>2023-11-13T06:19:03.000Z</published>
    <updated>2023-11-13T07:31:28.249Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：VGG网络详解<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、VGG 在2014年由牛津大学著名研究组 VGG（Visual Geometry Group）提出。</p><p>2、VGG网络的创新点<br>（1）通过堆叠多个小卷积核来替代大尺度卷积核，可以减少训练参数，同时能保证相同的感受野。<br>（2）论文中提到，可以通过堆叠两个3×3的卷积核替代5x5的卷积核，堆叠三个3×3的卷积核替代7x7的卷积核。</p><p>3、CNN感受野<br>（1）卷积神经网络中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野（receptive field）。<br>（2）通俗的解释是，输出feature map上的一个单元 对应 输入层上的区域大小。<br>（3）以下图为例，输出层 layer3 中一个单元 对应 输入层 layer2 上区域大小为2×2（池化操作），对应输入层 layer1 上大小为5×5（可以这么理解，layer2中 2×2区域中的每一块对应一个3×3的卷积核，又因为 stride=2，所以layer1的感受野为5×5）<br><img src="/pic/VGG%E7%BD%91%E7%BB%9C/gsy.jpg" alt="感受野"><br>（4）感受野的计算公式为：<br>&emsp; F(i)=(F(i+1)−1)×Stride +Ksize<br>&emsp;  * F(i) 为第i层感受野<br>&emsp; * Stride为第i层的步距<br>&emsp; * Ksize为 卷积核 或 池化核 尺寸<br>&emsp; 以上图为例：<br>&emsp; * Feature map: F ( 3 ) = 1<br>&emsp; * Pool1：F ( 2 ) = ( 1 − 1 ) × 2 + 2 = 2<br>&emsp; * Conv1: F ( 1 ) = ( 2 − 1 ) × 2 + 3 = 5</p><p>4、小卷积核<br>（1）堆叠两个3×3的卷积核替代5x5的卷积核，堆叠三个3×3的卷积核替代7x7的卷积核。替代前后感受野是否相同？<br>（注：VGG网络中卷积的Stride默认为1）<br>&emsp; Feature map: F = 1 F=1F=1<br>&emsp; * Conv3x3(3): F = ( 1 − 1 ) × 1 + 3 = 3<br>&emsp; * Conv3x3(2): F = ( 3 − 1 ) × 1 + 3 = 5 （5×5卷积核感受野）<br>&emsp; * Conv3x3(1): F = ( 5 − 1 ) × 1 + 3 = 7 （7×7卷积核感受野）</p><p>（2）堆叠3×3卷积核后训练参数是否真的减少了？<br>&emsp; 注：CNN参数个数 = 卷积核尺寸×卷积核深度 × 卷积核组数 = 卷积核尺寸 × 输入特征矩阵深度 × 输出特征矩阵深度。<br>&emsp; 现假设 输入特征矩阵深度 = 输出特征矩阵深度 = C<br>&emsp; *使用7×7卷积核所需参数个数：7 × 7 × C × C = 49 C**2<br>&emsp; *堆叠三个3×3的卷积核所需参数个数：3 × 3 × C × C + 3 × 3 × C × C + 3 × 3 × C × C = 27 C**2 </p><p>5、VGG-16<br>（1）VGG网络有多个版本，一般常用的是VGG-16模型，其网络结构如下如所示：<br><img src="/pic/VGG%E7%BD%91%E7%BB%9C/VGG16.jpg" alt="VGG16"><br>（2）稍作计算可以发现，经3×3卷积的特征矩阵的尺寸是不改变的：</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：VGG网络详解</summary>
    
    
    
    <category term="研究方向(学习路线_记忆宫殿)" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91-%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="阶段四：图像分类实战" scheme="https://mapao0110.github.io/tags/%E9%98%B6%E6%AE%B5%E5%9B%9B%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>计算机视觉三大顶会</title>
    <link href="https://mapao0110.github.io/2023/11/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B8%89%E5%A4%A7%E9%A1%B6%E4%BC%9A/"/>
    <id>https://mapao0110.github.io/2023/11/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B8%89%E5%A4%A7%E9%A1%B6%E4%BC%9A/</id>
    <published>2023-11-13T04:39:14.000Z</published>
    <updated>2023-11-13T04:57:01.153Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：带你了解ICCV、ECCV、CVPR三大国际会议<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、前言<br>（1）作为刚入门CV的新人，有必要记住计算机视觉方面的三大顶级会议：ICCV,CVPR,ECCV，统称为ICE。<br>（2）与其它学术领域不同，计算机科学使用会议而不是期刊作为发表研究成果的主要方式。<br>2、ICCV、ECCV、CVPR是什么？<br>（1）ICCV 的全称是 IEEE International Conference on Computer Vision，即国际计算机视觉大会，是公认的三个会议中级别最高的。它的举办地方会在世界范围内选，每两年召开一次。<br>（2）ECCV的全称是European Conference on Computer Vision，即欧洲计算机视觉国际会议。每两年召开一次，与ICCV正好错开。<br>（3）CVPR全称是IEEE Conference on Computer Vision and Pattern Recognition，即IEEE国际计算机视觉与模式识别会议。该会议一般在6月举行，举办地是美国，是一个一年一次的会议。<br>3、三大会议链接<br>（1）ICCV:<a href="http://www.informatik.uni-trier.de/~ley/db/conf/iccv/index.html">http://www.informatik.uni-trier.de/~ley/db/conf/iccv/index.html</a><br>（2）ECCV： <a href="http://www.informatik.uni-trier.de/~ley/db/conf/eccv/index.html">http://www.informatik.uni-trier.de/~ley/db/conf/eccv/index.html</a><br>（3）CVPR：<a href="http://dblp.uni-trier.de/db/conf/cvpr/index.html">http://dblp.uni-trier.de/db/conf/cvpr/index.html</a></p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：带你了解ICCV、ECCV、CVPR三大国际会议</summary>
    
    
    
    <category term="研究方向(学习路线_记忆宫殿)" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91-%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="阶段二：预备知识学习阶段" scheme="https://mapao0110.github.io/tags/%E9%98%B6%E6%AE%B5%E4%BA%8C%EF%BC%9A%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0%E9%98%B6%E6%AE%B5/"/>
    
  </entry>
  
  <entry>
    <title>计算机体系结构</title>
    <link href="https://mapao0110.github.io/2023/11/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    <id>https://mapao0110.github.io/2023/11/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</id>
    <published>2023-11-12T12:36:31.000Z</published>
    <updated>2023-11-12T12:36:31.904Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：博文简介(XXX)<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、<br>（1）</p><p>2、<br>（1）</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：博文简介(XXX)</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>高级人工智能</title>
    <link href="https://mapao0110.github.io/2023/11/12/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    <id>https://mapao0110.github.io/2023/11/12/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/</id>
    <published>2023-11-12T12:28:24.000Z</published>
    <updated>2023-12-08T08:10:35.869Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：研一期末高级人工智能复习<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、大题<br>（1）遗传算法<br>（2）人工神经网络<br>（3）专家系统</p><p>2、论述题<br>（1）知识与知识表示<br>（2）搜索策略<br>（3）机器学习<br>（4）进化计算</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：研一期末高级人工智能复习</summary>
    
    
    
    <category term="研一期末复习_记忆宫殿" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E4%B8%80%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="高级人工智能" scheme="https://mapao0110.github.io/tags/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>面向对象分析与设计</title>
    <link href="https://mapao0110.github.io/2023/11/12/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1/"/>
    <id>https://mapao0110.github.io/2023/11/12/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1/</id>
    <published>2023-11-12T12:26:00.000Z</published>
    <updated>2023-11-12T12:26:00.387Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：博文简介(XXX)<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、<br>（1）</p><p>2、<br>（1）</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：博文简介(XXX)</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>机器学习</title>
    <link href="https://mapao0110.github.io/2023/11/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    <id>https://mapao0110.github.io/2023/11/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</id>
    <published>2023-11-12T12:18:02.000Z</published>
    <updated>2023-11-12T12:55:58.910Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：机器学习与sklearn<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、算法选择指导<br>（1）如果数据量小于50，一般是无法使用sklearn的机器学习算法建模的。<br>（2）如果数据有类别标签，请使用分类模型。<br>（3）如果数据需要预测精确值，请使用回归模型。<br>（4）如果想查看数据分布情况，可以考虑使用降维算法。<br>（5）如果数据没有类别标签，可以使用聚类算法。</p><p>2、<br>（1）</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：机器学习与sklearn</summary>
    
    
    
    <category term="研究方向(学习路线_记忆宫殿)" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91-%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="阶段一：机器学习" scheme="https://mapao0110.github.io/tags/%E9%98%B6%E6%AE%B5%E4%B8%80%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>研究生综合英语1</title>
    <link href="https://mapao0110.github.io/2023/11/11/%E7%A0%94%E7%A9%B6%E7%94%9F%E7%BB%BC%E5%90%88%E8%8B%B1%E8%AF%AD1/"/>
    <id>https://mapao0110.github.io/2023/11/11/%E7%A0%94%E7%A9%B6%E7%94%9F%E7%BB%BC%E5%90%88%E8%8B%B1%E8%AF%AD1/</id>
    <published>2023-11-11T06:39:03.000Z</published>
    <updated>2023-11-11T06:39:03.916Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：博文简介(XXX)<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、<br>（1）</p><p>2、<br>（1）</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：博文简介(XXX)</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>新时代中国特色社会主义理论与实践</title>
    <link href="https://mapao0110.github.io/2023/11/11/%E6%96%B0%E6%97%B6%E4%BB%A3%E4%B8%AD%E5%9B%BD%E7%89%B9%E8%89%B2%E7%A4%BE%E4%BC%9A%E4%B8%BB%E4%B9%89%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
    <id>https://mapao0110.github.io/2023/11/11/%E6%96%B0%E6%97%B6%E4%BB%A3%E4%B8%AD%E5%9B%BD%E7%89%B9%E8%89%B2%E7%A4%BE%E4%BC%9A%E4%B8%BB%E4%B9%89%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/</id>
    <published>2023-11-11T06:38:24.000Z</published>
    <updated>2023-11-11T06:38:24.827Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：博文简介(XXX)<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、<br>（1）</p><p>2、<br>（1）</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：博文简介(XXX)</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>矩阵论复习</title>
    <link href="https://mapao0110.github.io/2023/11/11/%E7%9F%A9%E9%98%B5%E8%AE%BA%E5%A4%8D%E4%B9%A0/"/>
    <id>https://mapao0110.github.io/2023/11/11/%E7%9F%A9%E9%98%B5%E8%AE%BA%E5%A4%8D%E4%B9%A0/</id>
    <published>2023-11-11T06:37:34.000Z</published>
    <updated>2023-11-17T11:53:52.521Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：研一期末矩阵论复习<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="考点01（线性空间与线性变换）"><a href="#考点01（线性空间与线性变换）" class="headerlink" title="考点01（线性空间与线性变换）"></a>考点01（线性空间与线性变换）</h3><p>1、基变换与坐标变换<br>（1）基变换：新基=旧基<em>p<br>（2）坐标变换：新坐标=p逆</em>旧坐标<br>（3）正交化（施密特）<br>（4）习题：p6-例题11、p32-11-12</p><h3 id="考点02（Jordan标准形）"><a href="#考点02（Jordan标准形）" class="headerlink" title="考点02（Jordan标准形）"></a>考点02（Jordan标准形）</h3><p>1、Jordan矩阵<br>（1）p44-例题(5-7)_特别是例7(向量重选)、p59-(12、13)</p><p>2、最小多项式：尝试法(20分)</p><h3 id="考点03（矩阵的分解）"><a href="#考点03（矩阵的分解）" class="headerlink" title="考点03（矩阵的分解）"></a>考点03（矩阵的分解）</h3><p>1、满秩分解(M-P逆)</p><p>2、奇异值分解(20分)</p><h3 id="考点04（矩阵的广义逆）"><a href="#考点04（矩阵的广义逆）" class="headerlink" title="考点04（矩阵的广义逆）"></a>考点04（矩阵的广义逆）</h3><p>1、求M-P逆(p99-例3)(满秩分解)</p><h3 id="考点05（矩阵分析）"><a href="#考点05（矩阵分析）" class="headerlink" title="考点05（矩阵分析）"></a>考点05（矩阵分析）</h3><p>1、求范数(V,M)</p><p>2、求矩阵函数e^A，sinA<br>（1）p135-15</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：研一期末矩阵论复习</summary>
    
    
    
    <category term="研一期末复习_记忆宫殿" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E4%B8%80%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="矩阵论" scheme="https://mapao0110.github.io/tags/%E7%9F%A9%E9%98%B5%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>常用快捷键随记</title>
    <link href="https://mapao0110.github.io/2023/11/11/%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E9%9A%8F%E8%AE%B0/"/>
    <id>https://mapao0110.github.io/2023/11/11/%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E9%9A%8F%E8%AE%B0/</id>
    <published>2023-11-11T05:52:51.000Z</published>
    <updated>2023-11-11T06:00:25.805Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：电脑常用快捷键随记<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、截图<br>（1）win10自带：Win+Shift+S</p><p>2、系统控制<br>（1）任务管理器：Ctrl+Shift+Esc</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：电脑常用快捷键随记</summary>
    
    
    
    <category term="工具小世界" scheme="https://mapao0110.github.io/categories/%E5%B7%A5%E5%85%B7%E5%B0%8F%E4%B8%96%E7%95%8C/"/>
    
    
    <category term="电脑办公" scheme="https://mapao0110.github.io/tags/%E7%94%B5%E8%84%91%E5%8A%9E%E5%85%AC/"/>
    
  </entry>
  
  <entry>
    <title>数理统计复习</title>
    <link href="https://mapao0110.github.io/2023/11/09/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%A4%8D%E4%B9%A0/"/>
    <id>https://mapao0110.github.io/2023/11/09/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%A4%8D%E4%B9%A0/</id>
    <published>2023-11-09T14:23:43.000Z</published>
    <updated>2023-11-12T07:35:03.634Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：研一期末数理统计复习<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="考点01"><a href="#考点01" class="headerlink" title="考点01"></a>考点01</h3><p>1、数理统计的基本概念<br>（1）样本均值、样本方差、修正样本方差、样本标准差、样本k阶原点矩及样本k阶中心距(书：p4)<br>（2）样本中位数、极差，经验分布函数(书：p8、p9)<br>（3）分位数、抽样分布定理(书：p21、p22)<br>（4）三大分布：卡方分布、T分布、F分布<br>（5）伽马函数(书：p12)</p><p>2、课后习题<br>（1）1.6(书：p27)、1.13(书：p29)</p><h3 id="考点02"><a href="#考点02" class="headerlink" title="考点02"></a>考点02</h3><p>1、参数估计<br>（1）无偏估计及有效估计(p84-2.8)<br>（2）矩估计(多个未知参数)及极大似然估计(p82-2.1-2.2)<br>&emsp; 书：p32&lt;-&gt;p33-例2.1.2、例2.1.3及拓展的其它重要分布<br>（3）区间估计(p70-p76、例2.4.1)</p><h3 id="考点03"><a href="#考点03" class="headerlink" title="考点03"></a>考点03</h3><p>1、假设检验<br>（1）p98-例3.2.2-例3.2.4</p><h3 id="考点04"><a href="#考点04" class="headerlink" title="考点04"></a>考点04</h3><p>1、最小二乘法<br>（1）p175</p><h3 id="考点05"><a href="#考点05" class="headerlink" title="考点05"></a>考点05</h3><p>1、双因素方差分析<br>（1）方差分析表(p150)<br>（2）p151-例4.2.1</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：研一期末数理统计复习</summary>
    
    
    
    <category term="研一期末复习_记忆宫殿" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E4%B8%80%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="数理统计" scheme="https://mapao0110.github.io/tags/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>AlexNet</title>
    <link href="https://mapao0110.github.io/2023/11/09/AlexNet/"/>
    <id>https://mapao0110.github.io/2023/11/09/AlexNet/</id>
    <published>2023-11-09T09:58:00.000Z</published>
    <updated>2023-11-09T14:03:01.181Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：AlexNet神经网络模型训练<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>卷积神经网络（Convolutional Neural Networks, CNN）<br>1、该网络的亮点：<br>（1）首次利用GPU进行网络加速训练<br>（2）使用了ReLU激活函数<br>（3）使用了LRN局部响应归一化<br>（4）在全连接层的前两层中使用了Dropout随机失活神经元操作，以减少过拟合。</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：AlexNet神经网络模型训练</summary>
    
    
    
    <category term="研究方向(学习路线_记忆宫殿)" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91-%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="阶段四：图像分类实战" scheme="https://mapao0110.github.io/tags/%E9%98%B6%E6%AE%B5%E5%9B%9B%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>LeNet</title>
    <link href="https://mapao0110.github.io/2023/11/09/LeNet/"/>
    <id>https://mapao0110.github.io/2023/11/09/LeNet/</id>
    <published>2023-11-09T09:27:43.000Z</published>
    <updated>2023-11-09T14:03:39.541Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：LeNet神经网络模型训练<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、requires_grad<br>（1）在pytorch中，tensor有一个requires_grad参数，如果设置为True，则反向传播时，该tensor就会自动求导。tensor的requires_grad的属性默认为False,若一个节点（叶子变量：自己创建的tensor）requires_grad被设置为True，那么所有依赖它的节点requires_grad都为True（即使其他相依赖的tensor的requires_grad = False）<br>（2）当requires_grad设置为False时,反向传播时就不会自动求导了，因此大大节约了显存或者说内存。<br>（3）值得注意的是：requires_grad的设置只能针对叶子结点（网络的权重w就算，bias也算），如何理解叶子结点呢？叶子节点在数据结构中是一棵树没有子节点的结点，在网络中就是这个结点对应的参数不是由更上一层的tensor计算而来。</p><p>2、with torch.no_grad()<br>（1）在该模块下，所有计算得出的tensor的requires_grad都自动设置为False。<br>（2）即使一个tensor（命名为x）的requires_grad = True，在with torch.no_grad计算，由x得到的新tensor（命名为w-标量）requires_grad也为False，且grad_fn也为None,即不会对w求导。<br>（3）在神经网络训练过程中，测试阶段及预测阶段不需要更新网络参数，使用该模块大大节约了内存的开销。</p><p>3、内存与显存的区别<br>（1）电脑内存是替CPU暂存资料的储存空间。<br>（2）显卡显存是替GPU（显卡芯片）暂存资料的储存空间。<br>（3）内存或显存理论上越大越好。<br>（4）笔记本内存是可以增加的，但是显卡我们一般不能更换，笔记本大多是独立显示芯片或核显。</p><p>4、demo的流程<br>（1）model.py ——定义LeNet网络模型<br>（2）train.py ——加载数据集并训练，训练集计算loss，测试集计算accuracy，保存训练好的网络参数<br>（3）predict.py——得到训练好的网络参数后，用自己找的图像进行分类测试</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：LeNet神经网络模型训练</summary>
    
    
    
    <category term="研究方向(学习路线_记忆宫殿)" scheme="https://mapao0110.github.io/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91-%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF-%E8%AE%B0%E5%BF%86%E5%AE%AB%E6%AE%BF/"/>
    
    
    <category term="阶段四：图像分类实战" scheme="https://mapao0110.github.io/tags/%E9%98%B6%E6%AE%B5%E5%9B%9B%EF%BC%9A%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>Pycharm导包遇到的问题</title>
    <link href="https://mapao0110.github.io/2023/11/08/Pycharm%E5%AF%BC%E5%8C%85%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://mapao0110.github.io/2023/11/08/Pycharm%E5%AF%BC%E5%8C%85%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2023-11-08T13:04:36.000Z</published>
    <updated>2023-11-09T14:00:38.222Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：Pycharm导包遇到的小问题及解决办法。<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、Pycharm中导入matplotlib遇到问题，但在控制台(cmd、conda)中pip list能够找到matplotlib包<br>（1）原因：因为在anaconda中创建了tensorflow、pytorch等多个虚拟环境，第一次在tensorflow中安装了matplotlib，所以pip list能够看到matplotlib安装包，<br>但在pytorch下因为没有安装所以找不到module。<br>（2）搞心态：此时在pycharm中install matplotlib会显示失败，在cdm和conda中pip install matplotlib也会失败，仿佛怎么也弄不好。<br>（3）解决办法：进入anaconda prompt，然后进入pytorch环境（activate pytorch）,再在里面通过pip install matplotlib安装包，问题解决。<br>（4）举一反三：在切换python解释器的时候，其它相应的包如果遇到同样的问题，可对症下药。</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：Pycharm导包遇到的小问题及解决办法。</summary>
    
    
    
    <category term="深度学习_随心所欲" scheme="https://mapao0110.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%9A%8F%E5%BF%83%E6%89%80%E6%AC%B2/"/>
    
    
    <category term="Pycharm导包" scheme="https://mapao0110.github.io/tags/Pycharm%E5%AF%BC%E5%8C%85/"/>
    
  </entry>
  
  <entry>
    <title>图像处理杂记</title>
    <link href="https://mapao0110.github.io/2023/11/02/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%9D%82%E8%AE%B0/"/>
    <id>https://mapao0110.github.io/2023/11/02/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%9D%82%E8%AE%B0/</id>
    <published>2023-11-02T08:56:40.000Z</published>
    <updated>2023-11-09T13:55:40.552Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：图像处理相关小知识点<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><ol><li><p>图像灰度化：</p><p> （1）图像灰度化是将一幅彩色图像转换为灰度图像的过程。在灰度图像中，每个像素只包含一个灰度值，而不是彩色图像中的红、绿和蓝三个通道。灰度图像通常用于简化图像处理和分析，因为它们只包含亮度信息，而没有颜色信息。</p></li><li><p>图像二值化：<br> （1）图像二值化（Image Binarization）是一种图像处理技术，它将一幅灰度图像转换为只包含两个像素值的二值图像，通常是黑色（0）和白色（255）或其他两种互斥的颜色。二值化的目标是将图像中的信息从背景中分离出来，以便更容易进行特征提取、分割和分析。<br> （2）图像二值化的主要思想是根据像素的灰度值将图像分为两个不同的区域：前景和背景。前景通常包含我们感兴趣的目标对象，而背景则是目标对象的周围环境。通过将前景和背景分离成明显不同的像素值，可以更容易地进行目标检测、分割、轮廓提取等图像处理任务。</p></li><li><p>图像灰度化和二值化的区别：<br> （1）灰度处理会保留图像中所有的灰度层级，而二值化则只能保留黑白两种颜色，所以在某些场景下，灰度处理能够更好地保留图像的细节，而二值化则可以更好地突出图像中的边界和轮廓。</p></li><li><p>图像加噪：<br> （1）图像加噪是指在一幅图像中引入不希望的、随机或人为制造的像素值的变化，这些变化可能来自于各种源头，包括传感器噪声、环境条件、传输问题、图像采集设备的问题或意图明确的操作。噪声可以干扰或损害图像的质量，使其更难以分析、处理或识别。</p></li></ol><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：图像处理相关小知识点</summary>
    
    
    
    <category term="深度学习_随心所欲" scheme="https://mapao0110.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%9A%8F%E5%BF%83%E6%89%80%E6%AC%B2/"/>
    
    
    <category term="图像处理" scheme="https://mapao0110.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch基础</title>
    <link href="https://mapao0110.github.io/2023/10/31/PyTorch%E5%9F%BA%E7%A1%80/"/>
    <id>https://mapao0110.github.io/2023/10/31/PyTorch%E5%9F%BA%E7%A1%80/</id>
    <published>2023-10-31T11:19:19.000Z</published>
    <updated>2023-11-13T07:27:07.415Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：PyTorch相关基础概念<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><ol><li><p>计算图：用来描述运算的有向无环图<br>（1）计算图有两个主要元素：结点（Node）和边（Edge）；<br>（2）结点表示数据，如向量、矩阵、张量，边表示运算，如加减乘除卷积等；<br><img src="/pic/PyTorch%E5%9F%BA%E7%A1%80/jstu.png" alt="计算图表示"><br>（3）PyTorch基于动态图，TensorFlow基于静态图<br>静态图框架好比C++，每次修改之后运行都要重新编译才行，动态图框架好比Python，动态执行，可以交互式查看修改。</p></li><li><p>节点和结点的区别：节点，被认为是一个实体，有处理能力，比如：网络上的一台计算机；而结点则只是一个交叉点，像“结绳记事”，打个结，做个标记，仅此而已，一般算法中点的都是结点。</p></li><li><p>PyTorch的设计遵循tensor-&gt;variable(autograd)-&gt;nn.Module三个由低到高的抽象层次，分别代表高维数组（张量）、自动求导（变量）和神经网络（层/模块）。</p></li></ol><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：PyTorch相关基础概念</summary>
    
    
    
    <category term="深度学习_随心所欲" scheme="https://mapao0110.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E9%9A%8F%E5%BF%83%E6%89%80%E6%AC%B2/"/>
    
    
    <category term="PyTorch" scheme="https://mapao0110.github.io/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>博客模板</title>
    <link href="https://mapao0110.github.io/2023/10/31/%E5%8D%9A%E5%AE%A2%E6%A8%A1%E6%9D%BF/"/>
    <id>https://mapao0110.github.io/2023/10/31/%E5%8D%9A%E5%AE%A2%E6%A8%A1%E6%9D%BF/</id>
    <published>2023-10-31T07:16:15.000Z</published>
    <updated>2023-11-09T13:46:34.580Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：博客模板制作<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、<br>（1）</p><p>2、<br>（1）</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：博客模板制作</summary>
    
    
    
    <category term="Hexo_博客随记" scheme="https://mapao0110.github.io/categories/Hexo-%E5%8D%9A%E5%AE%A2%E9%9A%8F%E8%AE%B0/"/>
    
    
    <category term="博客模板" scheme="https://mapao0110.github.io/tags/%E5%8D%9A%E5%AE%A2%E6%A8%A1%E6%9D%BF/"/>
    
  </entry>
  
  <entry>
    <title>Hexo-GitHub</title>
    <link href="https://mapao0110.github.io/2023/10/29/hexo-github/"/>
    <id>https://mapao0110.github.io/2023/10/29/hexo-github/</id>
    <published>2023-10-29T11:19:16.000Z</published>
    <updated>2023-11-12T06:42:52.032Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><ul><li>个人微信公众号： Mn2+</li><li><a href="https://blog.csdn.net/Mnpao?type=blog">个人博客首页</a></li><li>注：学习交流使用！</li><li>本文简介：Hexo本地编写博文的相关操作<span id="more"></span></li></ul><hr><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>1、使用hexo创建博文，然后部署到GitHub<br>（1）新建博文：hexo new ‘xxx’<br>（2）清除缓存文件：hexo clean<br>（3）生成网站静态文件到默认设置的 public 文件夹：hexo g<br>（4）自动生成网站静态文件，并部署到设定的仓库：hexo d<br>（5）本地浏览：hexo s<br>（6）hexo插入图片：在Hexo的目录source中创建一个图片文件夹，例如pic。<br>&emsp; 把你要插入的图片文件放到该目录下面，在你的文章中正常使用markdown的语法插入图片即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![img](&#x2F;pic&#x2F;xxx.png)</span><br></pre></td></tr></table></figure><p>2、博客默认布局设置<br>（1）如何自定义布局呢？实际上，布局是一个markdown文件，它们保存在scaffolds/目录下，可以看到hexo自带的三种布局其实就是三个.md文件。</p><p>3、Markdowm的基本使用<br>（1）多少个#号就是多少级标题<br>&emsp; 由于不同 Markdown 应用程序处理 # 和标题之间空白格的方式并不一致，出于兼容性考虑，最好在 # 与标题之间使用一个空格。井号的个数即表示是几级标题，最低可到六级标题，七个井号时就不再有标题效果了。<br>（2）添加列表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- 列表1</span><br><span class="line">         a 子列表</span><br><span class="line">         b 子列表</span><br><span class="line">- 列表2</span><br></pre></td></tr></table></figure><p>&emsp; 这样就可以添加列表，挺好tab后可以添加子列表<br>（3）添加链接</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[baidu](http:&#x2F;&#x2F;www.baidu.com)</span><br></pre></td></tr></table></figure><p>&emsp; []中是简介，()中是连接<br>（4）添加图片</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![image](&#x2F;images&#x2F;xxx.xxx)</span><br></pre></td></tr></table></figure><p>（5）斜体</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*斜体*</span><br></pre></td></tr></table></figure><p>&emsp; 在星号中间写文章<br>（6）字体加粗</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">**粗体**</span><br></pre></td></tr></table></figure><p>&emsp; 同上，只不过换成两个星号<br>（7）代码块<br>&emsp; 通过tab上面的那个英文符号，两点是单行，六点是多行<br>（8）添加引用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; 引用</span><br></pre></td></tr></table></figure><p>&emsp; 当某段内容出自某人之口或者某篇文章时，使用引用可以方便地把引用的部分分开，告诉读者这一段是出自别处。<br>（9）添加横线</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">---或者------------------------或者***等方式</span><br></pre></td></tr></table></figure><p>（10）markdown段落中如何产生缩进<br>（粗暴添加）直接在文本前加html中的空格语句</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&amp;nbsp; 半角的不断行的空白格（推荐使用）</span><br><span class="line">&amp;ensp;  半角的空格 </span><br><span class="line">&amp;emsp;  全角的空格</span><br></pre></td></tr></table></figure><p>（11）hexo整合pdf.js<br>&emsp;  首先，安装hexo-pdf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-pdf </span><br></pre></td></tr></table></figure><p>&emsp;  其次，修改项目的 _config.yml配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">post_asset_folder: true</span><br></pre></td></tr></table></figure><p>&emsp;  然后，在source_posts下创建(xxx)目录，放入pdf文件<br>&emsp;  最后，创建与上面目录相同名的md文件；注意：md文件的名称一定要与第三步创建的目录同名，如我的目录是PDF01，那 md 文件名为PDF01.md。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;embed src&#x3D;&quot;.&#x2F;xxx.pdf&quot; width&#x3D;&quot;100%&quot; height&#x3D;&quot;750&quot; type&#x3D;&quot;application&#x2F;pdf&quot;&gt;</span><br></pre></td></tr></table></figure><p>&emsp;  在md文件里面添加上述代码；说明：src的路径就为pdf文件的路径，不用加PDF01前缀，因为这个PDF01.md文件默认会找PDF01下的文件。</p><hr><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li><p>个人微信公众号：Mn2+</p></li><li><p>哔哩哔哩：不爱码字的小懒马儿</p></li><li><p><a href="https://github.com/mapao0110/mapao0110.github.io">GitHub</a></p></li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;个人微信公众号： Mn2+&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/Mnpao?type=blog&quot;&gt;个人博客首页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;注：学习交流使用！&lt;/li&gt;
&lt;li&gt;本文简介：Hexo本地编写博文的相关操作</summary>
    
    
    
    <category term="Hexo_博客随记" scheme="https://mapao0110.github.io/categories/Hexo-%E5%8D%9A%E5%AE%A2%E9%9A%8F%E8%AE%B0/"/>
    
    
    <category term="Hexo万花筒" scheme="https://mapao0110.github.io/tags/Hexo%E4%B8%87%E8%8A%B1%E7%AD%92/"/>
    
  </entry>
  
</feed>
